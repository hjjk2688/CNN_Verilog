# FPGA 기반 터치패드 연동 실시간 CNN 가속기 최종 프로젝트 보고서

## 1. 서론 (Introduction)

최근 인공지능 기술이 엣지(Edge) 디바이스로 확산됨에 따라, 제한된 자원 환경에서 AI 연산을 효율적으로 수행하는 것이 핵심 과제로 부상했습니다. 일반적인 CPU는 순차 처리 방식의 한계로 인해 실시간 AI 추론에 요구되는 높은 성능과 전력 효율을 동시에 만족시키기 어렵습니다. 이에 대한 효과적인 해결책으로, 하드웨어 수준에서 병렬 처리가 가능한 FPGA(Field-Programmable Gate Array)가 주목받고 있으며, 본 프로젝트는 FPGA를 활용한 하드웨어 가속의 실질적인 가능성을 입증하고자 합니다.

본 프로젝트의 핵심 목표는 **'터치패드를 통해 입력된 손글씨 데이터를 실시간으로 인식하기 위해, Zynq-7000 SoC 플랫폼의 이기종 컴퓨팅 모델을 활용하여 고도로 최적화된 CNN 하드웨어 가속기를 설계하고 구현하는 것'** 입니다. 이를 통해 AI 모델링부터 RTL 설계, 임베디드 시스템 통합까지 아우르는 End-to-End 시스템 구축 역량을 확보하고자 합니다.

구현된 시스템의 전체적인 데이터 흐름은 다음과 같은 3단계로 요약할 수 있습니다.

1. **입력 (Input)**: 사용자가 터치패드에 손글씨를 입력합니다.
2. **연산 (Computation)**: FPGA에 구현된 CNN 가속기가 입력 데이터를 받아 실시간으로 추론 연산을 수행합니다.
3. **출력 (Output)**: 인식된 숫자 결과를 VGA 디스플레이를 통해 시각적으로 표시합니다.

본 보고서는 제안하는 시스템의 아키텍처부터 하드웨어 상세 설계, 구현 결과 및 성과에 이르기까지 프로젝트 전반의 기술적 내용을 체계적으로 기술할 것입니다. 다음 장에서는 시스템의 근간을 이루는 전체 아키텍처에 대해 상세히 설명하겠습니다.

## 2. 전체 시스템 구조 (Overall System Architecture)

본 시스템은 Zynq SoC의 핵심 특징인 PS(Processing System)와 PL(Programmable Logic)을 활용한 하드웨어/소프트웨어 공동 설계(Co-design)를 기반으로 합니다. PS의 ARM 코어가 전체 시스템 제어와 데이터 준비를 담당하고, PL의 FPGA 영역에는 맞춤형으로 설계된 CNN 가속기가 배치되어 실제 연산을 수행합니다. 이러한 이기종 컴퓨팅 아키텍처는 소프트웨어의 유연성과 하드웨어의 압도적인 성능을 동시에 확보하는 최적의 솔루션입니다.

### 2.1. 데이터 흐름 및 시스템 구성도

시스템의 데이터는 명확하게 정의된 파이프라인을 따라 처리됩니다. 각 단계는 AXI(Advanced eXtensible Interface) 프로토콜을 통해 유기적으로 연결되어 고속 데이터 전송을 보장합니다.

1. **입력 (Touchpad)**: 터치패드로부터 수집된 손글씨 좌표 데이터는 PS에서 28x28 이미지로 전처리된 후 DDR 메모리에 저장됩니다.
2. **데이터 전송 (AXI DMA)**: PS의 제어에 따라 AXI DMA가 DDR 메모리에서 이미지 데이터를 읽어 AXI-Stream 프로토콜 기반의 데이터 패킷으로 변환하여 PL 영역으로 고속 전송합니다.
3. **CNN 가속 (FPGA PL)**: PL에 위치한 CNN 가속기 IP는 스트림 데이터를 실시간으로 수신하여 합성곱, 풀링, 완전 연결 등 모든 추론 연산을 하드웨어적으로 처리합니다.
4. **결과 전달 및 출력 제어 (Zynq PS)**: CNN 가속기에서 최종 판별된 숫자(0~9) 결과는 PS로 전달됩니다. PS는 이 결과를 바탕으로 VGA 디스플레이에 출력할 화면을 제어합니다.
5. **시각화 (VGA IP)**: PS의 제어에 따라 AXI VDMA가 DDR 메모리의 프레임 버퍼를 읽어 VGA 컨트롤러로 전송하고, 최종적으로 모니터에 결과가 실시간으로 표시됩니다.

시스템을 구성하는 주요 IP(Intellectual Property)와 그 역할은 아래 표와 같습니다.

| 구성 요소 | 역할 | 적용 인터페이스 |
|----------|------|----------------|
| Zynq PS | 시스템 전체 제어, 데이터 전처리, IP 구동 및 결과 처리 | AXI4-Lite (제어), AXI4-MM (데이터) |
| AXI DMA | DDR 메모리와 PL IP 간의 고속 메모리-스트림 데이터 전송 | AXI4-Memory Map / AXI4-Stream |
| AXI VDMA | DDR 내 비디오 프레임 버퍼를 관리하고 VGA 컨트롤러로 전송 | AXI4-Memory Map / AXI4-Stream |
| Data FIFO | 클럭 도메인 동기화 및 데이터 속도 차이를 완충하는 버퍼 | AXI4-Stream (비동기 모드) |
| Width Converter | 데이터 버스 폭 정렬 (AXI 32bit → CNN IP 8bit) | AXI4-Stream |
| CNN 가속기 (cnn_top) | CNN 추론 연산의 핵심을 수행하는 맞춤형 하드웨어 로직 | AXI4-Stream |
| VGA Controller | AXI-Stream 데이터를 받아 VGA 타이밍 신호를 생성 및 출력 | AXI4-Stream → Physical I/O |

### 2.2. AI 모델 아키텍처

본 가속기에 구현된 CNN은 두 개의 합성곱/풀링 블록과 하나의 완전 연결 계층으로 구성된 경량화 모델입니다. 입력 이미지가 각 계층을 통과하며 데이터의 형태(Shape)가 변화하는 과정은 다음과 같습니다.

| 단계 | 레이어 | 입력 크기 | 연산 | 출력 크기 |
|-----|--------|----------|------|----------|
| 0 | Input Image | - | - | 28 x 28 x 1 |
| 1 | Conv 1 | 28 x 28 x 1 | 5x5 Kernel, 3 Filters | 24 x 24 x 3 |
| 2 | Max Pool 1 | 24 x 24 x 3 | 2x2 Pooling | 12 x 12 x 3 |
| 3 | Conv 2 | 12 x 12 x 3 | 5x5 Kernel, 3 Filters | 8 x 8 x 3 |
| 4 | Max Pool 2 | 8 x 8 x 3 | 2x2 Pooling | 4 x 4 x 3 |
| 5 | Flatten | 4 x 4 x 3 | - | 48 |
| 6 | Dense (FC) | 48 | - | 10 |

### 2.3. 클럭 도메인 전략

시스템의 안정성과 성능을 최적화하기 위해, 각 IP의 요구 사항에 맞춰 3개의 독립적인 클럭 도메인을 구성했습니다.

| 클럭 도메인 | 주파수 | 적용 모듈 | 설계 근거 |
|-----------|--------|----------|----------|
| 시스템 클럭 | 50 MHz | Zynq PS, DMA, VDMA, AXI Interconnect | DDR 메모리 인터페이스와의 고속 데이터 전송 효율 최적화 |
| VGA 클럭 | 25.175 MHz | VGA Controller | VGA 640×480@60Hz 해상도의 표준 비디오 타이밍 규격 준수 |
| CNN 클럭 | 10 MHz | CNN 가속기 | 복잡한 이진 덧셈 트리(Binary Adder Tree) 파이프라인이 타이밍 위반 없이 단일 클럭 내에 완료되도록 보장하고, 설계 초기 단계에서 라우팅 복잡도를 완화하며 디버깅 용이성을 증대 |

서로 다른 클럭 속도로 동작하는 도메인 간의 데이터 전송에서 발생할 수 있는 CDC(Clock Domain Crossing) 문제는 **비동기 FIFO(Asynchronous FIFO)**를 통해 해결했습니다. 시스템에 배치된 AXI4-Stream Data FIFO IP를 Independent Clock 모드로 설정하여, 50MHz의 시스템 클럭과 10MHz의 CNN 클럭 간의 속도 차이를 안전하게 완충하고 데이터 무결성을 완벽하게 보장합니다.

이처럼 견고하게 설계된 시스템 아키텍처는 본 프로젝트의 핵심인 CNN 가속기가 최대의 성능을 발휘할 수 있는 안정적인 기반을 제공합니다. 다음 장에서는 가속기의 내부 상세 설계에 대해 심층적으로 분석하겠습니다.

## 3. CNN 가속기 상세 설계 (Detailed Design)

본 장에서는 CNN 가속기의 핵심 성능을 결정하는 RTL(Verilog) 수준의 설계 최적화 기법들을 다룹니다. 단순히 기능을 구현하는 것을 넘어, Verilog 코드가 어떻게 특정 하드웨어 동작(파이프라인, 병렬 처리, 자원 재사용)을 구현했는지 코드 스니펫과 함께 심층 분석함으로써, 하드웨어 아키텍처에 대한 깊이 있는 이해를 제시합니다.

### 3.1. 하드웨어 친화적 양자화: 고정 스케일링 (Fixed Scaling)

FPGA의 제한된 리소스를 효율적으로 사용하기 위해 복잡한 부동소수점 연산을 배제하고 INT8 고정소수점 연산을 채택했습니다. 특히, 본 시스템의 입력 데이터가 터치패드를 통해 생성되는 0 또는 1의 이진(Binary) 데이터라는 특성에 착안하여, 하드웨어 복잡도를 획기적으로 낮추는 고정 스케일링(Fixed Scaling) 기법을 적용했습니다.

이 기법의 핵심은 signed 8-bit 정수(-128 ~ +127)의 표현 범위를 최대로 활용하는 것입니다. 스케일링 계수로 표현 가능한 가장 큰 양수인 127을 선택함으로써, 정수 변환 과정에서의 정보 손실을 최소화하고 정밀도를 극대화했습니다.

그러나 이 방식은 연산 과정에서 '스케일 폭발(Scale Explosion)' 문제를 야기합니다. 127배로 스케일링된 두 INT8 값이 곱해지면, 그 결과는 $127^2 \approx 2^{14}$배로 스케일이 커지게 됩니다. 다음 계층으로 전달하기 전, 이 값을 다시 128($2^7$)배 수준으로 낮추는 리스케일링(Re-scaling) 과정이 필수적입니다. 이때, 하드웨어에서 매우 비싼 연산인 나눗셈기를 사용하는 대신, 우측 비트 시프트(`>>> 7`) 연산으로 대체하여 DSP(Digital Signal Processing) 자원을 절약하고 타이밍 마진을 확보하는 최적화를 수행했습니다.

```verilog
// conv_calc 모듈
// 나눗셈(/128) 대신 우측 시프트(>>>7)를 사용하여 DSP 블록을 절약
conv_out_calc <= ($signed(final_sum_s7) >>> 7) + BIAS_VALUE;
```

마지막으로, 본 프로젝트는 최종 결과로 '어떤 숫자가 가장 높은 점수를 가졌는가(Argmax)'만을 요구합니다. 모든 출력값에 동일한 스케일이 적용되어 있으므로 값들의 순위(대소 관계)는 변하지 않습니다. 따라서 자원을 소모하는 역양자화(De-quantization) 과정을 생략하여 추가적인 하드웨어 절약 효과를 얻었습니다.

### 3.2. 중앙 제어 로직 (cnn_top.v)

가속기 전체의 데이터 흐름과 상태를 관장하기 위해 5단계 FSM(Finite State Machine)을 설계했습니다.

* **S_IDLE**: 시스템 초기화 및 시작(start_sw) 신호 대기
  * start_sw 입력 시 → S_RUN_CNN
* **S_RUN_CNN**: AXI-Stream 인터페이스를 통해 외부로부터 이미지 데이터를 수신
  * 마지막 데이터(tlast) 수신 시 → S_PADDING
* **S_PADDING**: 파이프라인 플러싱(Pipeline Flushing) 수행
  * 일정 시간(padding_cnt) 경과 후 → S_WAIT_DONE
* **S_WAIT_DONE**: 완전 연결 계층의 연산 완료 신호 대기
  * fc_valid 신호 감지 시 → S_RESULT
* **S_RESULT**: 최종 추론 결과를 출력하고 S_IDLE로 복귀 준비
  * start_sw 해제 시 → S_IDLE

본 가속기는 깊은 파이프라인 구조를 가지므로, 외부 데이터 입력이 끝난 후에도 내부 레지스터에는 아직 처리 중인 데이터가 남아있습니다. 이러한 데이터를 유실 없이 끝까지 처리하기 위한 파이프라인 플러싱 전략이 필수적입니다. S_PADDING 상태는 바로 이 문제를 해결하기 위해 고안되었습니다. 이 상태에서는 외부 데이터 입력을 차단하고 '0'을 강제로 주입하여, 파이프라인 내부에 남아있는 유효 데이터를 끝까지 밀어냅니다.

```verilog
// cnn_top.v
localparam S_IDLE = 3'd0, S_RUN_CNN = 3'd1, S_PADDING = 3'd2, ...;

// S_PADDING 상태일 때 외부 데이터 대신 0(검정색)을 강제 주입
assign cnn_data_in = (state == S_PADDING) ? 8'd0 : s_axis_tdata;

// padding_cnt를 이용해 일정 시간 동안 플러싱을 유지
if (state == S_PADDING && padding_cnt > 2000) state <= S_WAIT_DONE;
```

### 3.3. 합성곱 연산 계층 (conv_layer.v)

합성곱 연산은 전체 시스템의 성능 병목 구간이므로, 이를 해결하기 위해 데이터 재사용과 극단적인 병렬 처리라는 두 가지 핵심 전략을 적용했습니다. 이는 성능을 위해 하드웨어 자원을 최대로 투입하는 '전력투구(all-out)' 방식의 아키텍처입니다.

첫째, **라인 버퍼(Line Buffer)** 를 사용하여 메모리 접근을 최적화했습니다. 이는 하드웨어 Shift Register Array를 구현한 것으로, 1차원 픽셀 스트림을 입력받으면서도 매 클럭 2차원 공간 정보(5x5 윈도우)를 유지할 수 있게 해주는 스트림 처리의 핵심 기법입니다. 전체 이미지(28x28=784 픽셀)를 저장하는 대신, 연산에 필요한 단 5줄의 데이터(5x28=140 픽셀)만 저장하여 메모리 사용량을 82% 절감했습니다.

```verilog
// conv_buf 모듈
// 매 클럭, 데이터가 한 줄씩 위로 이동하며 저장됨 (Data Reuse)
line4_regs[col_cnt] <= line3_regs[col_cnt];
line3_regs[col_cnt] <= line2_regs[col_cnt];
line2_regs[col_cnt] <= line1_regs[col_cnt];
line1_regs[col_cnt] <= data_in;
```

둘째, 5x5 커널 연산(25개의 곱셈과 24개의 덧셈)을 고속으로 처리하기 위해 이진 덧셈 트리(Binary Adder Tree) 파이프라인 구조를 적용했습니다. 25개의 곱셈 결과를 순차적으로 더하면 신호 지연 경로(Critical Path)가 길어져 클럭 속도를 높일 수 없습니다. 이진 덧셈 트리는 토너먼트 대진표처럼 두 개씩 짝을 지어 계층적으로 더해나가는 방식으로, Critical Path를 획기적으로 단축시켜 높은 클럭 속도에서도 안정적인 동작을 가능하게 합니다. 아래 코드는 Verilog의 for-loop가 어떻게 25개의 곱셈기를 물리적으로 생성하여 완전 병렬(Fully Parallel) 구조를 구현하는지 보여줍니다.

```verilog
// conv_calc 모듈
// for-loop는 하드웨어에서 25개의 곱셈기를 물리적으로 생성함
for (i = 0; i < 25; i = i + 1) begin
    product1_s1[i] <= $signed(p_s0[i]) * get_w1(i);
end
```

### 3.4. 완전 연결 계층 (fully_connected.v)

합성곱 계층이 속도 극대화를 위해 병렬 구조를 채택한 것과 달리, 완전 연결 계층(FC Layer)은 의도적인 아키텍처 트레이드오프의 결과로 자원 효율성을 극대화하기 위해 시분할(Time-Sharing) 연산 구조로 설계되었습니다. FC 계층은 합성곱 계층보다 연산량이 적으므로, 단 하나의 MAC(Multiply-Accumulate) 연산기를 FSM 제어를 통해 재사용하여 DSP와 같은 고비용 자원을 절약하고, 이를 성능이 더 중요한 합성곱 계층에 할당하는 전략적 선택을 했습니다.

또한 시스템 안정성 확보를 위해, input_buffer에 데이터를 쓰는 로직을 제어 FSM이 포함된 always 블록과 분리했습니다. 이는 리셋 신호가 제어 로직에만 영향을 미치고 데이터 저장 로직에는 영향을 주지 않도록 하여, 의도치 않은 메모리 오염(corruption)을 방지하는 효과적인 FPGA 설계 기법입니다.

## 4. 구현 결과 및 성과 (Implementation Results & Achievements)

본 장에서는 설계된 CNN 가속기의 성능을 정량적으로 평가하고, 동일 알고리즘을 PC 환경에서 실행했을 때와 비교 분석합니다. 더 나아가, 프로젝트를 통해 달성한 기술적 성과와 그 의의를 종합적으로 논의합니다.

### 4.1. 성능 분석 (Performance Analysis)

구현된 FPGA 가속기의 성능을 검증하기 위해, 동일한 CNN 알고리즘을 PC(CPU) 환경에서 최적화하여 실행한 결과와 추론 시간을 비교했습니다.

| 구분 | PC (Software) | FPGA (Hardware) |
|-----|---------------|-----------------|
| 플랫폼 | Intel/AMD CPU (일반 PC) | Xilinx Zynq-7000 SoC |
| 동작 클럭 | 수 GHz | 10 MHz |
| 연산 방식 | 순차 처리 (Sequential / SIMD) | 완전 병렬 처리 (Fully Parallel) |
| 총 추론 시간 | 0.5374 ms | 0.2787 ms |
| 처리 속도 (FPS) | 약 1,860 FPS | 약 3,588 FPS |

분석 결과, 10MHz라는 매우 낮은 클럭으로 동작하는 FPGA 가속기가 수 GHz의 고성능 PC CPU보다 약 1.93배 빠른 성능을 기록했습니다. 이러한 결과의 핵심 원인은 다음과 같습니다.

1. **압도적인 사이클 효율성**: PC는 운영체제 오버헤드, 명령어 디코딩 등으로 인해 실제 연산 외에 많은 클럭을 소모합니다. 반면, 본 가속기는 데이터 처리 파이프라인이 고도로 최적화되어, 단 2,787 클럭 사이클 만에 하나의 이미지에 대한 모든 추론 연산을 완료합니다.

2. **병렬 처리의 힘**: CPU가 기본적으로 순차 처리에 의존하는 반면, FPGA 가속기는 낮은 클럭 속도의 한계를 극복하기 위해 대규모 병렬 구조를 채택했습니다. 특히 Conv2 계층에서 하나의 출력 특징맵을 계산하기 위해 3개의 입력 채널에 대한 5x5 커널 연산(25 x 3 = 75개의 곱셈)이 병렬로 처리되면서 전체 처리 시간을 획기적으로 단축시켰습니다.

3. **결정론적 레이턴시 (Deterministic Latency)**: CPU는 OS 스케줄링 및 캐시 상태에 따라 실행 시간이 미세하게 변동(Jitter)될 수 있지만, FPGA 가속기는 입력이 시작되면 언제나 정확히 2,787 사이클 후에 결과가 출력됨을 보장합니다. 이는 실시간성이 중요한 임베디드 시스템에서 결정적인 장점입니다.

### 4.2. 핵심 성과 및 의의

본 프로젝트를 통해 달성한 핵심 기술적 성과는 다음과 같습니다.

1. **Full-Stack 시스템 설계 역량 확보**: AI 모델링(SW)부터 RTL 하드웨어 설계(HW), 임베디드 시스템 통합에 이르기까지 AI 가속기 개발의 전 과정을 직접 구축하며 영역 간 상호작용에 대한 깊이 있는 이해를 확보했습니다.

2. **하드웨어 최적화 사고방식 체득**: 성능이 병목인 합성곱 계층에는 **'속도 중심의 병렬 처리'**를, 상대적으로 연산량이 적은 완전 연결 계층에는 **'자원 중심의 직렬 처리'**를 적용하는 등, 목표에 따라 최적의 아키텍처를 선택하는 전략적 트레이드오프 분석 능력을 체득했습니다.

3. **SoC 표준 인터페이스 마스터**: 산업 표준인 AXI-Stream 프로토콜의 valid/ready 핸드셰이크 메커니즘을 완벽히 이해하고, ILA(Integrated Logic Analyzer)를 활용하여 실제 하드웨어에서 발생하는 타이밍 문제를 실시간으로 디버깅하는 실무 능력을 확보했습니다.


#### 4.3. 결론
본 프로젝트는 Zynq-7000 SoC 플랫폼을 활용하여 터치패드 입력부터 CNN 연산, VGA 출력까지 이어지는 End-to-End 실시간 AI 추론 시스템을 성공적으로 구현했습니다. 
이는 10MHz의 낮은 클럭으로 동작하는 맞춤형 하드웨어 패브릭이 극단적인 병렬 처리와 사이클 효율성을 통해 수 GHz의 범용 프로세서를 능가할 수 있음을 보여주는 아키텍처 수준 최적화 의 성공적인 사례입니다.
특히, 데이터 재사용을 극대화한 라인 버퍼, Critical Path를 단축시킨 이진 덧셈 트리, 그리고 성능과 자원 간의 균형을 맞춘 병렬/직렬 아키텍처의 전략적 선택은 단순히 하나의 프로젝트 완성을 넘어, 
향후 더 복잡하고 깊은 신경망을 FPGA에 구현하기 위한 견고한 **'아키텍처적 청사진(Architectural Blueprint)'**을 마련했다는 점에서 큰 의의를 가집니다.
