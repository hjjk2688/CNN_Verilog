Zybo Z7-20 기반 CNN 가속기 설계 및 구현 최종 보고서

1. 프로젝트 개요 (Project Overview)

본 보고서는 Zybo Z7-20 SoC 플랫폼을 기반으로 고성능 MNIST 손글씨 인식 NPU(Neural Processing Unit)의 성공적인 End-to-End 설계 및 구현 과정을 상세히 기술한다. 본 프로젝트는 Zynq SoC의 이기종 컴퓨팅(Heterogeneous Computing) 모델을 활용하여, 소프트웨어로 정의된 AI 모델을 고도로 병렬화된 하드웨어 가속기로 이식하는 Edge AI 추론 시스템의 실현 가능성을 입증하는 것을 핵심 목표로 삼았다.

프로젝트의 핵심 정체성은 다음과 같다.

* 프로젝트 명: FPGA 기반 고속 MNIST 손글씨 숫자 인식 NPU 구현
* 핵심 목표: CPU/GPU가 아닌 FPGA의 병렬성을 활용한 CNN 연산 하드웨어 가속
* 대상 하드웨어: Zybo Z7-20 (Xilinx Zynq-7000 SoC)
* 핵심 기술: RTL(Verilog) 설계, AXI 프로토콜 기반 시스템 통합, HW/SW Co-design

최종적으로 본 프로젝트는 다음과 같은 세 가지 핵심 성과를 성공적으로 달성했다.

1. SW 모델의 완벽한 HW 구현: TensorFlow로 학습된 CNN 모델을 비트 단위까지 정확하게 동작하는 Verilog HDL 모듈로 변환 및 검증 완료.
2. 고성능 병렬 아키텍처 설계: 3D Convolution 연산을 1클럭당 1픽셀씩 처리하는 고도의 파이프라인 및 병렬 구조 설계로 처리 속도 극대화.
3. 안정적인 시스템 통합: Zynq SoC의 PS와 PL을 AXI 버스로 연결하고, 복수의 클럭 도메인을 안정적으로 동기화하여 시스템 안정성 확보.

이러한 성과들은 다음 장에서 상세히 기술할 견고하고 세심하게 설계된 시스템 아키텍처를 기반으로 한다.

2. 시스템 아키텍처 (System Architecture)

본 시스템의 아키텍처는 Zynq SoC의 핵심 특징인 PS(Processing System)와 PL(Programmable Logic)의 이기종 컴퓨팅 모델을 적극적으로 활용하여 설계되었다. PS의 ARM 코어가 전체 시스템 제어 및 데이터 준비를 담당하고, PL의 FPGA 영역에는 맞춤형으로 설계된 CNN 가속기와 데이터 전송 IP들이 배치되어 실제 연산을 수행하는 구조이다. 안정성과 성능을 위해 데이터 경로와 클럭 도메인은 명확하게 분리되었다.

프로젝트의 최종 Vivado Block Design에 기반한 시스템 구성 요소와 그 역할은 다음과 같다.

* PS (ARM Core): 시스템 제어, IP 구동, DDR 메모리로의 데이터 준비 및 최종 결과 처리 등 소프트웨어 로직을 담당한다.
* PL (FPGA): 커스텀 CNN 가속기 IP, 데이터 전송용 AXI DMA, 비디오 출력용 AXI VDMA 등 핵심 하드웨어 로직이 탑재되는 영역이다.
* DDR 메모리: PS와 PL이 공유하는 핵심 데이터 저장 공간으로, 입력 이미지와 최종 결과 이미지가 이곳에 저장된다.
* AXI Interconnect: PS와 다수의 PL IP 간의 통신을 중재하는 중앙 허브 역할을 수행하며, 주소 기반 라우팅을 통해 데이터 트랜잭션을 관리한다.

각 IP는 단순한 기능 블록이 아닌 전략적 선택의 결과이다. AXI DMA는 CPU의 개입 없이 대량의 데이터를 전송하여 시스템 처리량을 극대화하기 위해 채택되었다. AXI VDMA는 일반 DMA와 달리 2D 프레임 버퍼와 순환 버퍼링(Circular Buffering)에 대한 이해가 내장되어 있어 실시간 비디오 스트리밍에 최적화된 솔루션이다. 마지막으로 AXI Data FIFO는 서로 다른 클럭 도메인을 안전하게 연결(CDC)하는 역할과 더불어, CNN IP가 데이터를 처리할 준비가 되지 않았을 때 발생하는 백프레셔(Backpressure)를 효과적으로 처리하는 버퍼 역할까지 겸한다.

2.1 CNN 추론 경로

CNN 추론을 위한 데이터는 다음과 같은 파이프라인을 통해 처리된다.

PS 제어 → AXI DMA (DDR to Stream) → AXI Data FIFO → AXI Stream Data Width Converter → CNN IP

이 경로에서 각 구성 요소의 역할은 다음과 같다.

* AXI DMA: PS의 제어를 받아 DDR 메모리에 저장된 이미지 데이터를 읽어 AXI-Stream 프로토콜 기반의 데이터 패킷으로 변환하여 PL로 고속 전송한다.
* AXI Data FIFO: 시스템 클럭(50MHz) 도메인과 CNN 클럭(10MHz) 도메인 간의 안전한 데이터 전송을 보장하는 비동기 버퍼 역할을 수행한다.
* AXI Stream Data Width Converter: 메모리 처리량에 최적화된 32비트 AXI 버스와 픽셀 단위 처리에 최적화된 8비트 CNN IP 인터페이스 간의 데이터 폭 불일치(Data Width Mismatch) 문제를 해결한다.

2.2 비디오 출력 경로

추론 결과를 모니터에 표시하기 위한 비디오 데이터 경로는 다음과 같다.

PS (결과 이미지 DDR에 저장) → AXI VDMA (DDR to Stream) → VGA Controller → 모니터 출력

2.3 클럭 도메인 전략

시스템은 각 IP의 요구 성능과 동작 안정성을 고려하여 3개의 독립적인 클럭 도메인으로 구성되었다. 초기 설계에서는 여러 Clocking Wizard IP를 사용하려 했으나 핀 충돌 및 라우팅 에러가 발생하여, 최종적으로는 Zynq PS 내부의 PLL을 활용해 FCLK_CLK0, 1, 2를 직접 생성 및 분배하는 안정적인 방식을 채택했다.

도메인	클럭 속도	담당 IP	설계 근거
시스템 클럭	50 MHz	DMA, VDMA, AXI Interconnect	고속 버스 및 DDR 메모리와의 효율적인 데이터 전송
VGA 클럭	25 MHz	VGA Controller, VDMA (Stream)	640x480@60Hz 해상도의 안정적인 비디오 타이밍 규격 준수
CNN 클럭	10 MHz	CNN 가속기 IP	복잡한 덧셈 트리(Adder Tree)의 타이밍 마진을 확보하고 디버깅 용이성 증대

이처럼 견고하게 설계된 하드웨어 아키텍처가 원활하게 동작하기 위해서는, 처리할 데이터를 정밀하게 가공하고 관리하는 정교한 소프트웨어 전략이 필수적이다.

3. AI 모델 및 소프트웨어 전략

성공적으로 소프트웨어 정의 AI 모델을 실리콘에 매핑하기 위해서는, 추상적인 수학적 연산과 물리적 하드웨어 제약 사이의 간극을 메우는 면밀한 소프트웨어 전략이 요구된다. 본 섹션에서는 하드웨어 효율을 극대화하기 위해 적용된 데이터 전처리, 모델 아키텍처 분석, 가중치 변환, 그리고 수치 최적화 기법을 상세히 설명한다.

3.1 AI 모델 아키텍처

본 프로젝트에서 구현한 CNN은 두 개의 Convolution/Pooling 블록과 하나의 Fully Connected 레이어로 구성된 경량화 모델이다. 각 레이어를 통과하며 데이터 차원이 변화하는 과정은 다음과 같다.

단계	레이어 (Layer)	입력 크기 (Input)	연산 (Kernel/Pool)	출력 크기 (Output)	비고
0	Input Image	-	-	28 x 28 x 1	MNIST 원본
1	Conv 1	28 x 28 x 1	5x5, Valid	24 x 24 x 3	특징 추출
2	Max Pool 1	24 x 24 x 3	2x2	12 x 12 x 3	차원 축소
3	Conv 2	12 x 12 x 3	5x5, Valid	8 x 8 x 3	심층 특징 추출
4	Max Pool 2	8 x 8 x 3	2x2	4 x 4 x 3	최종 차원 축소
5	Flatten	4 x 4 x 3	-	48	1차원 벡터화
6	Dense (FC)	48	-	10	최종 분류

3.2 데이터 전처리 파이프라인

표준 이미지 파일을 Verilog HDL이 인식할 수 있는 ROM(Read-Only Memory) 형태로 변환하기 위해 다음과 같은 전처리 파이프라인을 구축했다.

단계	처리 내용	핵심 설명
1단계	Grayscale 변환	3채널 컬러 이미지를 1채널 흑백으로 변환하여 연산량 감소
2단계	색상 반전	MNIST 데이터셋 표준(검은 배경, 흰 글씨)에 포맷 일치
3단계	크기 조정	모든 이미지를 모델 입력 규격인 28x28로 표준화 (BILINEAR 보간법)
4단계	양자화 (Scaling)	(pixel / 255.0) × 127 연산으로 Float32를 Int8로 변환, 메모리 75% 절약
5단계	코드 생성	**희소 코딩(Sparse Coding)**을 적용하여 배경(값 0)을 생략, Verilog ROM 코드 길이 70% 단축

3.3 핵심 전략: 가중치 재배열 (Transpose)

소프트웨어 프레임워크(Keras)와 맞춤형 FPGA 하드웨어는 데이터를 읽는 순서가 다르기 때문에, 하드웨어의 병렬 연산 구조에 맞춰 가중치 순서를 재배열(Transpose)하는 것이 필수적이다. 특히 Conv2 계층의 재배열은 프로젝트 성능을 좌우하는 핵심이었다.

계층	Keras 원본 (Shape)	FPGA 변환 (Transpose)	최종 형태	설계 의도 (Rationale)
Conv1	(5, 5, 1, 3)	.transpose(3, 0, 1, 2)	(Out, Row, Col, In)	출력 필터(Out) 기준으로 하드웨어 모듈을 분리 설계했기 때문에 Out을 맨 앞으로 배치.
Conv2	(5, 5, 3, 3)	.transpose(3, 2, 0, 1)	(Out, In, Row, Col)	[핵심] 각 하드웨어 모듈이 3개의 입력 채널(In)을 동시에 처리하도록 설계. 가중치 순서를 하드웨어 데이터 흐름에 완벽히 일치시킴.
FC	(48, 10)	.transpose(1, 0)	(Neuron, Input)	10개의 뉴런이 48개 입력을 순차적으로 누적 계산하는 직렬 구조에 맞게 변경.

3.4 자원 절약을 위한 양자화 기술

Q1. 왜 스케일링에 127을 사용했는가?

본 프로젝트는 signed 8-bit 정수(-128 ~ +127) 자료형을 사용한다. 0.0에서 1.0 사이의 실수 값을 이 자료형으로 변환할 때, 표현 가능한 양수 중 가장 큰 값인 127을 곱하면 정수 표현 범위를 최대한 활용하여 정보 손실을 최소화하고 정밀도를 극대화할 수 있다.

Q2. >>> 7 (Right Shift) 연산의 정체는?

이는 리스케일링(Re-scaling) 연산이다. 127배로 스케일링된 값 두 개가 곱해지면 스케일은 127×127배로 커진다. 이 값을 다음 레이어로 전달하기 전에 다시 128배(2^7) 수준으로 낮춰야 한다. 하드웨어에서 나눗셈은 매우 비싼 연산이지만, 2의 거듭제곱으로 나누는 것은 비용이 없는 비트 시프트 연산(>>> 7)으로 대체할 수 있어 리소스를 크게 절약한다.

Q3. 왜 역양자화(De-quantization)가 필요 없는가?

프로젝트의 최종 목표는 각 숫자의 정확한 확률 점수를 계산하는 것이 아니라, 가장 높은 점수를 가진 숫자(Argmax)를 찾는 것이다. 모든 최종 출력값에 동일한 상수가 곱해져 있더라도 값들의 대소 관계(순위)는 변하지 않는다. 따라서 굳이 자원을 낭비하며 실수로 되돌리는 역양자화 과정 없이, 정수 상태에서 최댓값을 찾아도 결과는 100% 동일하다.

이러한 소프트웨어 전략들은 다음 장에서 설명할 하드웨어 모듈의 물리적 구현에 직접적으로 반영되었다.

4. 하드웨어(RTL) 핵심 모듈 설계

본 프로젝트의 CNN 가속기는 자원 재활용, 병렬 처리, 파이프라이닝이라는 세 가지 핵심 철학을 바탕으로 각 레이어의 연산 특성을 고려하여 Verilog HDL로 직접 설계되었다. 이는 제한된 FPGA 자원 내에서 최대의 성능을 이끌어내기 위한 전략적 선택이었다.

  * 핵심 아이디어: 전체 이미지(784 픽셀) 대신 연산에 필요한 **단 5줄(140 픽셀)**의 데이터만 저장하여 5x5 슬라이딩 윈도우를 구현.
  * 설계 효과: 전체 이미지 저장 방식 대비 레지스터/BRAM 사용량 82% 절감 달성.
  * 핵심 아이디어: 3개의 Line Buffer를 병렬 배치하여 3채널 특징맵을 동시에 처리. 5x5 커널과 3개 입력 채널에 필요한 75개의 곱셈기(DSP)를 병렬로 사용하여 3D Convolution을 단일 클럭 사이클 내에 완료.
  * 설계 효과: **1 클럭 당 1 픽셀 처리(1 Pixel / 1 Clock)**라는 높은 처리 속도 달성.
  * 핵심 아이디어: 대량의 자원 소모를 피하기 위해 병렬 처리 대신 직렬 누적(Serial Accumulation) 아키텍처를 채택. 하나의 계산 유닛이 48개 입력을 순차적으로 처리하며 곱셈기를 재활용.
  * 설계 효과: FC 계층의 하드웨어 리소스를 최소화하여 전체 설계의 집적도 향상.
  * 핵심 아이디어: 'Smart Reset' 기능을 구현하여 이미지 처리 완료 시 자동으로 시스템을 초기화.
  * 설계 효과: 외부 리셋 없이 연속 테스트 및 시연이 가능하여 사용자 편의성 증대.
Conv2 레이어와 Fully Connected 레이어의 아키텍처적 분기는 하드웨어 최적화의 핵심 원칙을 보여준다. 성능이 병목이었던 Conv2에는 75개의 DSP를 소모하는 공격적인 병렬 아키텍처를 적용하여 처리량을 극대화했다. 반면, FC 레이어에서는 자원 효율성을 우선순위로 두어 하드웨어 풋프린트를 최소화하는 직렬 누적 아키텍처를 채택했다. 이와 같은 의도적인 트레이드오프 분석은 전체 시스템에 걸쳐 성능과 자원 사용률의 균형을 맞추는 데 결정적이었다.

이처럼 강력한 하드웨어 설계는 이론적으로 완벽해 보였지만, 실제 구현 과정에서는 시스템 수준의 여러 난관에 부딪혔으며, 이를 해결하기 위한 체계적인 접근이 필요했다.

5. 핵심 이슈 및 해결 과정 (Troubleshooting)

본 섹션은 프로젝트 중 발생한 핵심적인 시스템 레벨의 문제들을 체계적으로 해결한 과정을 기록함으로써, 고급 디버깅 기술과 하드웨어-소프트웨어 상호작용에 대한 깊은 이해를 실증적으로 보여준다.

  * 문제 원인 분석: Conv2 모듈의 병렬 아키텍처는 5x5 커널 × 3 입력 채널 = 75개의 곱셈 연산을 매 클럭 동시에 수행해야 하므로, 최소 75개의 DSP 슬라이스를 요구한다. 프로젝트 초기 보드였던 Basys3는 90개의 DSP를 보유했지만, 이는 다른 시스템 IP들의 리소스 사용량을 고려할 때 절대적으로 부족한 수치였다.
  * 해결책: 더 많은 DSP 자원(220개)을 보유한 Zybo Z7-20 보드로 교체하여 설계 목표를 달성했다.
  * 문제 상황: 3개의 다른 클럭(50/25/10MHz)을 생성하기 위해 Clocking Wizard IP를 여러 개 사용하자 핀 충돌 및 라우팅 에러가 발생했다.
  * 해결책: 외부 IP 대신 Zynq PS의 내부 PLL을 활용하여 FCLK_CLK0, 1, 2를 활성화했다. 또한, 각 클럭 도메인의 안정적인 리셋 동기화를 위해 3개의 개별 Processor System Reset IP를 각 클럭 도메인마다 배치하여 시스템 전체의 안정성을 확보했다.
  * 문제 원인: ILA(Integrated Logic Analyzer)를 이용한 실시간 디버깅 결과, CNN IP가 생성하는 tlast 신호 타이밍이 AXI DMA의 예상과 불일치하여 AXI-Stream 프로토콜이 위반되는 것을 확인했다. 이로 인해 DMA의 마스터 상태 머신과 CNN IP의 슬레이브 상태 머신이 데드락(Deadlock) 상태에 빠져 데이터 흐름이 중단되었다.
  * 해결책: IP 내부의 출력 데이터 카운터 로직을 정밀하게 수정하여, 정확한 패킷 길이에 맞춰 tlast 신호를 생성하도록 변경하여 핸드셰이크 프로토콜을 완벽하게 만족시켰다.
이러한 문제 해결 과정을 통해 얻은 경험은 프로젝트의 최종 성과를 더욱 견고하게 만들었으며, 이는 다음 장의 정량적, 정성적 결과로 요약될 수 있다.

6. 프로젝트 성과 및 결론

본 프로젝트는 소프트웨어 AI 모델을 FPGA 하드웨어로 성공적으로 가속하는 Full-Stack 시스템을 구축함으로써 Zynq SoC 플랫폼의 잠재력을 입증했다. 설계 과정에서 적용된 다양한 최적화 전략은 다음과 같은 정량적 성과로 이어졌다.

항목	최적화 전략	달성 효과
메모리 자원	Line Buffer 설계	BRAM/레지스터 사용량 82% 절감
연산 자원	Int8 양자화	DSP 슬라이스 사용량 75% 절감 (Float32 대비)
처리 속도	Conv2 병렬 파이프라인	1 Pixel / 1 Clock 고속 처리 달성
회로 복잡도	시프트(>>>) 연산	나눗셈 로직 제거로 리소스 절약 및 타이밍 확보

본 프로젝트는 단순한 결과물 완성을 넘어 다음과 같은 핵심 엔지니어링 역량을 체득하는 중요한 계기가 되었다.

1. Full-Stack 시스템 설계 역량: AI 모델링(SW)부터 RTL 설계(HW), 임베디드 시스템 통합(System)까지 전 과정을 구축하며 영역 간 상호작용을 깊이 있게 이해.
2. 하드웨어 최적화 사고방식 체득: '어떻게 계산할까'를 넘어, **'어떻게 하면 더 적은 자원으로 더 빠르게 처리할까'**라는 하드웨어 중심의 사고방식을 함양. 이는 Conv2의 속도 중심 병렬 처리와 FC의 자원 중심 직렬 처리 선택이라는 트레이드오프 분석에서 드러남.
3. SoC 표준 인터페이스 마스터: AXI-Stream 프로토콜의 valid/ready 핸드셰이크 메커니즘을 완벽히 이해하고, ILA를 활용한 실시간 디버깅으로 실제 하드웨어 문제를 해결하는 능력 확보.

결론적으로, 본 프로젝트는 FPGA 기반 AI 가속기 설계의 전체 파이프라인을 성공적으로 완수하며, 하드웨어와 소프트웨어가 융합된 복잡한 시스템을 설계하고 구현할 수 있는 실질적인 역량을 입증했다. 이는 단순히 하나의 프로젝트 성공을 넘어, 향후 더 복잡한 신경망(e.g., ResNet)이나 첨단 양자화 기법을 적용할 수 있는 견고한 아키텍처적 청사진(Architectural Blueprint)을 마련했다는 점에서 그 의의가 크다.
