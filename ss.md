Zybo Z7-20 기반 CNN 가속기 설계 및 구현 최종 보고서

1. 프로젝트 개요 (Project Overview)

본 프로젝트는 Zynq SoC의 이기종 컴퓨팅(Heterogeneous Computing) 모델을 활용하여, 소프트웨어로 정의된 AI 모델을 고도로 병렬화된 하드웨어 가속기로 이식하는 Edge AI 추론 시스템의 실현 가능성을 입증하는 것을 핵심 목표로 삼았다. TensorFlow로 학습된 CNN 모델을 Zybo Z7-20 플랫폼 상에 End-to-End로 성공적으로 구현함으로써, 본 프로젝트는 소프트웨어 알고리즘을 하드웨어의 물리적 제약에 맞춰 최적화하는 과정에 대한 아키텍처적 해법과 깊이 있는 통찰을 제시한다.

* 프로젝트 명: FPGA 기반 고속 MNIST 손글씨 숫자 인식 NPU 구현
* 핵심 목표: CPU/GPU가 아닌 FPGA의 병렬성을 활용한 CNN 연산 하드웨어 가속
* 대상 하드웨어: Zybo Z7-20 (Xilinx Zynq-7000 SoC)
* 핵심 기술: RTL(Verilog) 설계, AXI 프로토콜 기반 시스템 통합, HW/SW Co-design

본 프로젝트는 다음 세 가지 핵심 기술적 성과를 달성했다.

1. SW 모델의 완벽한 HW 구현: TensorFlow 모델을 비트 단위까지 정확하게 동작하는 Verilog 모듈로 변환 및 검증 완료하였다. 이는 소프트웨어의 추상적 연산이 하드웨어의 물리적 로직으로 완벽하게 이식되었음을 의미한다.
2. 고성능 병렬 아키텍처 설계: 3D Convolution 연산을 1클럭당 1픽셀씩 처리하는 고도의 파이프라인 및 병렬 구조를 설계하여 처리 속도를 극대화했다. 이는 낮은 클럭에서도 높은 처리량을 달성하는 핵심 기반이 되었다.
3. 안정적인 시스템 통합: Zynq PS와 PL을 AXI 버스로 연결하고, 복수의 클럭 도메인을 안정적으로 동기화하여 시스템 안정성을 확보했다. 이를 통해 복잡한 SoC 환경에서의 시스템 통합 기술력을 입증하였다.

이러한 성과들은 다음 장에서 상세히 기술할 견고하고 세심하게 설계된 시스템 아키텍처를 기반으로 달성되었다.

2. 시스템 아키텍처 (System Architecture)

본 시스템의 아키텍처는 Zynq SoC의 핵심 특징인 PS(Processing System)와 PL(Programmable Logic)의 이기종 컴퓨팅 모델을 적극적으로 활용하여 설계되었다. PS의 ARM 코어가 전체 시스템 제어 및 데이터 준비와 같은 소프트웨어 로직을 담당하고, PL의 FPGA 영역에는 맞춤형으로 설계된 CNN 가속기와 데이터 전송 IP들이 배치되어 실제 연산을 수행하는 구조이다. 이 명확한 역할 분담은 시스템의 효율성과 안정성을 극대화하는 기반이 된다.

### 구성 요소 및 역할
| 구성 요소 | 위치 | 핵심 역할 |
| :--- | :--- | :--- |
| PS (ARM Core) | Zynq Processing System | 시스템 제어, IP 구동, DDR 메모리 관리, 최종 결과 처리 등 소프트웨어 로직 담당 |
| PL (FPGA) | Programmable Logic | 커스텀 CNN 가속기 IP, AXI DMA, AXI VDMA 등 핵심 하드웨어 로직 탑재 |
| DDR 메모리 | 공유 메모리 | PS와 PL이 공유하는 핵심 데이터 저장 공간 (입력/결과 이미지) |
| AXI Interconnect | PL | PS와 다수의 PL IP 간의 통신을 중재하는 중앙 허브 역할 |


CNN 추론 데이터 흐름

CNN 추론을 위한 데이터 파이프라인은 CPU의 개입을 최소화하고 데이터가 하드웨어 내에서 효율적으로 흐르도록 다음과 같이 설계되었다.

1. PS 제어: 추론할 이미지를 DDR 메모리에 준비.
2. AXI DMA: DDR 메모리로부터 이미지 데이터를 읽어 AXI-Stream 패킷으로 변환 후 고속 전송.
3. AXI Stream Data FIFO: **클럭 도메인 교차(CDC)**를 위한 비동기 버퍼 역할. 50MHz 시스템 클럭과 10MHz CNN 클럭 간의 안전한 데이터 전송 및 백프레셔(Backpressure) 처리.
4. AXI Stream Data Width Converter: 32-bit AXI 버스와 8-bit CNN IP 인터페이스 간의 데이터 폭 변환.
5. CNN IP: 변환된 픽셀 데이터를 입력받아 핵심 CNN 연산 수행.

VGA 출력 데이터 흐름

추론 결과를 모니터에 시각화하기 위한 비디오 데이터 경로는 실시간 스트리밍에 최적화된 VDMA를 중심으로 구성된다.

1. PS 제어: 추론 결과 이미지를 DDR 메모리에 저장.
2. AXI VDMA: DDR 메모리의 2D 프레임 버퍼를 읽어 AXI-Stream 비디오 데이터로 변환.
3. AXI Stream Data FIFO: 데이터 흐름을 안정화시키는 버퍼 역할.
4. VGA Controller: AXI-Stream 데이터를 입력받아 VGA 타이밍 신호(HSYNC, VSYNC) 생성.
5. 모니터 출력: 최종 VGA 신호를 통해 모니터에 결과 표시.

클럭 도메인 전략

시스템은 각 IP의 요구 성능과 동작 안정성을 고려하여 3개의 독립적인 클럭 도메인으로 구성되었다. 초기 설계의 불안정성을 해결하기 위해 외부 IP 대신 Zynq PS 내부의 안정적인 PLL을 활용하여 클럭을 생성 및 분배하는 방식을 채택했다.

도메인	클럭 속도	담당 IP	설계 근거
### 클럭 도메인 전략
| 도메인 | 클럭 속도 | 담당 IP | 설계 근거 |
| :--- | :--- | :--- | :--- |
| 시스템 클럭 | 50 MHz | DMA, VDMA, AXI Interconnect | 고속 버스 및 DDR 메모리와의 효율적인 데이터 전송 |
| VGA 클럭 | 25 MHz | VGA Controller, VDMA (Stream) | 640x480@60Hz 해상도의 안정적인 비디오 타이밍 규격 준수 |
| CNN 클럭 | 10 MHz | CNN 가속기 IP | 복잡한 덧셈 트리의 타이밍 마진 확보 및 디버깅 용이성 증대 |

이처럼 견고하게 설계된 하드웨어 아키텍처가 원활하게 동작하기 위해서는, 처리할 데이터를 정밀하게 가공하고 관리하는 정교한 소프트웨어 전략이 필수적이다.

3. AI 모델 및 최적화 전략 (AI Model & Optimization Strategy)

성공적으로 소프트웨어 정의 AI 모델을 실리콘에 매핑하기 위해서는, 추상적인 수학적 연산과 물리적 하드웨어 제약 사이의 간극을 메우는 면밀한 소프트웨어 전략이 요구된다. 하드웨어 효율을 극대화하기 위해 적용된 데이터 전처리, 가중치 변환, 그리고 수치 최적화 기법은 본 프로젝트 성공의 핵심 요인이다.

AI 모델 아키텍처

구현된 CNN은 두 개의 Convolution/Pooling 블록과 하나의 Fully Connected 레이어로 구성된 경량화 모델로, 각 레이어를 통과하며 데이터 차원이 변화하는 과정은 다음과 같다.

### AI 모델 아키텍처
| 단계 | 레이어 (Layer) | 입력 크기 (Input) | 연산 (Kernel/Pool) | 출력 크기 (Output) | 비고 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| 0 | Input Image | - | - | 28 x 28 x 1 | MNIST 원본 |
| 1 | Conv 1 | 28 x 28 x 1 | 5x5, Valid | 24 x 24 x 3 | 특징 추출 |
| 2 | Max Pool 1 | 24 x 24 x 3 | 2x2 | 12 x 12 x 3 | 차원 축소 |
| 3 | Conv 2 | 12 x 12 x 3 | 5x5, Valid | 8 x 8 x 3 | 심층 특징 추출 |
| 4 | Max Pool 2 | 8 x 8 x 3 | 2x2 | 4 x 4 x 3 | 최종 차원 축소 |
| 5 | Flatten | 4 x 4 x 3 | - | 48 | 1차원 벡터화 |
| 6 | Dense (FC) | 48 | - | 10 | 최종 분류 |

데이터 전처리 파이프라인

표준 이미지 파일을 Verilog HDL이 인식할 수 있는 ROM(Read-Only Memory) 형태로 변환하기 위해 다음과 같은 전처리 파이프라인을 구축했다.

1. Grayscale 변환: 3채널 컬러 이미지를 1채널 흑백으로 변환하여 연산량 감소.
2. 색상 반전: MNIST 데이터셋 표준(검은 배경, 흰 글씨)에 포맷 일치.
3. 크기 조정: 모든 이미지를 모델 입력 규격인 28x28로 표준화 (BILINEAR 보간법 사용).
4. 양자화 (Scaling): (pixel / 255.0) × 127 연산으로 Float32를 Int8로 변환하여 메모리 사용량 75% 절약.

가중치 재배열 전략

본 프로젝트의 가중치 재배열은 단순한 데이터 순서 변경이 아닌, 소프트웨어-하드웨어 Co-design의 핵심 철학을 담고 있다. 이는 소프트웨어가 하드웨어의 물리적 데이터 소비 방식을 완벽히 이해하고, 런타임 오버헤드 없이 데이터를 즉시 처리할 수 있는 형태로 미리 재구성하는 '데이터 계약(Data Contract)'을 수립하는 과정이다. 특히 Conv2 계층의 재배열((Out, In, Row, Col))은 3개의 입력 채널을 동시에 처리하는 병렬 하드웨어 구조에 데이터를 완벽하게 정렬시키기 위한 아키텍처적 선택이었다.

양자화 기술 심층 분석

* Q1. 왜 스케일링에 127을 사용했는가?
  * Signed 8-bit 정수(-128 ~ +127)의 표현 범위를 최대한 활용하여 정보 손실을 최소화하고 정밀도를 극대화하기 위함.
* Q2. >>> 7 (Right Shift) 연산의 역할은 무엇인가?
  * 리스케일링(Re-scaling) 연산. 하드웨어에서 비용이 큰 나눗셈(÷128)을 비용이 없는 비트 시프트 연산으로 대체하여 리소스를 크게 절약.
* Q3. 왜 역양자화(De-quantization)가 필요 없는가?
  * 최종 목표는 가장 높은 점수를 가진 숫자(Argmax)를 찾는 것이며, 모든 출력값의 대소 관계(순위)는 스케일링 상태에서도 변하지 않음. 따라서 불필요한 연산 자원 낭비를 방지.

이러한 소프트웨어 전략들은 다음 장에서 설명할 하드웨어 모듈의 물리적 구현에 직접적으로 반영되었다.

4. 핵심 하드웨어(RTL) 설계 (Core Hardware (RTL) Design)

본 CNN 가속기는 자원 재활용, 병렬 처리, 파이프라이닝이라는 세 가지 원칙을 '설계 선언(Design Manifesto)'으로 삼아 Verilog HDL로 직접 설계되었다. 이는 제한된 FPGA 자원 내에서 최대의 성능을 이끌어내기 위한 전략적 선택이었으며, 각 레이어의 연산 특성을 고려하여 차별화된 아키텍처를 적용했다.

* Conv1: Line Buffer 아키텍처
  * 핵심 아이디어: 전체 이미지가 아닌 연산에 필요한 **단 5줄(140 픽셀)**의 데이터만 저장하여 5x5 슬라이딩 윈도우 구현.
  * 설계 효과: 레지스터/BRAM 사용량 82% 절감 달성.
* Conv2: 극단적 병렬 처리 아키텍처
  * 핵심 아이디어: 3채널 특징맵을 동시에 처리. 5x5 커널과 3개 입력 채널에 필요한 75개의 곱셈기(DSP)를 병렬로 사용하여 3D Convolution을 단일 클럭 사이클 내에 완료.
  * 설계 효과: **1 클럭 당 1 픽셀 처리(1 Pixel / 1 Clock)**라는 높은 처리 속도 달성.
* Fully Connected: 직렬 누적 아키텍처
  * 핵심 아이디어: 대량의 자원 소모를 피하기 위해 병렬 처리 대신 직렬 누적(Serial Accumulation) 구조 채택. 하나의 계산 유닛이 곱셈기를 재활용.
  * 설계 효과: FC 계층의 하드웨어 리소스를 최소화하여 전체 설계의 집적도 향상.
* Main Controller: Smart Reset 기능
  * 핵심 아이디어: 이미지 처리 완료 시 자동으로 시스템을 초기화.
  * 설계 효과: 외부 리셋 없이 연속 테스트가 가능하여 사용자 편의성 증대.

설계 트레이드오프 분석

Conv2와 FC 레이어의 상반된 아키텍처는 의도적인 트레이드오프 분석의 결과이다. 성능 병목이었던 Conv2에는 공격적인 병렬 처리를 적용하여 처리량을 극대화했고, FC 레이어에는 자원 효율성을 우선으로 한 직렬 처리를 선택하여 하드웨어 풋프린트를 최소화했다. 이처럼 성능과 자원 사용률의 균형을 맞추는 것이 성공적인 하드웨어 설계의 핵심이다.

이처럼 강력하게 설계된 하드웨어가 실제 구현 과정에서 어떤 성능을 보였는지 정량적으로 분석하는 것은 프로젝트의 가치를 입증하는 데 필수적이다.

5. 성능 분석 및 비교 (Performance Analysis & Comparison)

구현된 FPGA 가속기의 추론 성능을 PC 환경과 정량적으로 비교하여 하드웨어 가속의 실질적인 효율성을 검증한다. 본 분석은 공정한 비교를 위해 PC 환경의 TensorFlow 코드를 Graph Mode로 최적화한 상태에서 진행되었으며, 단순히 '빠르다'는 결론을 넘어 '왜' 빠른지에 대한 아키텍처적 고찰을 제공하는 것을 목표로 한다.

실험 환경 비교

PC의 CPU는 수백 배 빠른 클럭 속도를 가졌지만, FPGA는 완전한 병렬 처리가 가능하다는 근본적인 아키텍처의 차이를 가집니다.

### 실험 환경 비교
| 구분 | PC (Software) | FPGA (Hardware) | 비고 |
| :--- | :--- | :--- | :--- |
| 플랫폼 | Intel/AMD CPU (General PC) | Xilinx Zynq-7000 (Zybo Z7-20) | - |
| 동작 클럭 | 수 GHz (Base Clock) | 10 MHz | PC가 약 수백 배 빠른 클럭 보유 |
| 구현 방식 | Python + TensorFlow (Graph Mode) | Verilog HDL (Full Custom Logic) | - |
| 연산 방식 | 순차 처리 (Sequential / SIMD) | 완전 병렬 처리 (Fully Parallel) | Conv2에서 75개 곱셈기 동시 동작 |


성능 측정 결과

측정 결과, 10MHz의 낮은 클럭으로 동작하는 FPGA 가속기가 최적화된 PC CPU 환경보다 약 1.93배 빠른 성능을 기록했다.

### 성능 측정 결과
| 비교 항목 | PC (CPU) 최적화 결과 | FPGA 가속기 (본 연구) | 개선율 (Speedup) |
| :--- | :--- | :--- | :--- |
| 총 추론 시간 | 0.5374 ms | 0.2787 ms | 약 1.93배 가속 |
| 처리 속도 (FPS) | 약 1,860 FPS | 약 3,588 FPS | - |

결과 심층 분석

10MHz FPGA가 수 GHz CPU보다 빠른 '역전 현상'의 원인은 다음과 같은 세 가지 아키텍처적 우위에서 비롯된다.

* 압도적인 사이클 효율성 (Cycle Efficiency): FPGA는 OS 오버헤드 없이 불과 2,787 사이클 만에 연산을 완료한다. 이는 **1 Pixel / 1 Clock**이라는 고효율 파이프라인 설계 덕분이다.
* 병렬 처리의 승리 (Parallelism vs Frequency): CPU의 순차 처리 방식과 달리, FPGA는 75개 DSP가 동시에 동작하는 대규모 병렬 구조로 낮은 클럭의 한계를 극복한다.
* 결정론적 레이턴시 (Deterministic Latency): FPGA는 시스템 부하와 무관하게 언제나 정확히 2,787 사이클에 결과가 출력되어 실시간성(Real-time)을 완벽하게 보장한다.

이러한 성공적인 성능을 달성하기까지는 여러 시스템 레벨의 난관을 극복하는 과정이 있었으며, 문제 해결 경험을 공유하는 것 또한 중요한 자산이다.

6. 핵심 이슈 및 해결 과정 (Troubleshooting)

본 섹션은 프로젝트 중 마주한 문제들을 단순한 버그 리포트가 아닌, 복잡한 SoC 설계에서 발생하는 고전적인 난제들을 해결한 사례로 제시한다. 이는 자원 계획, 다중 클럭 도메인 관리, 프로토콜 수준 통합 등 고급 시스템 디버깅 역량을 실증적으로 보여준다.

* 문제 1: DSP 자원 부족 (DSP Shortage)
  * 원인 분석: Conv2 모듈의 병렬 아키텍처는 75개의 DSP 슬라이스를 요구했다. 프로젝트 초기 보드였던 Basys3(90개 DSP)는 시스템 전체 리소스를 고려할 때 절대적으로 부족했다.
  * 해결책: 더 많은 DSP 자원(220개)을 보유한 Zybo Z7-20 보드로 교체하여 설계 목표를 타협 없이 달성했다.
* 문제 2: 클럭 생성 및 리셋 동기화 실패 (Clocking & Reset Failure)
  * 문제 상황: 여러 Clocking Wizard IP 사용 시 핀 충돌 및 라우팅 에러가 발생하여 시스템이 불안정해졌다.
  * 해결책: 외부 IP 대신 Zynq PS의 내부 PLL을 활용하여 FCLK_CLK0, 1, 2를 직접 생성했다. 또한, 각 클럭 도메인마다 개별 Processor System Reset IP를 배치하여 안정적인 리셋 동기화를 구현, 시스템 안정성을 확보했다.
* 문제 3: AXI-Stream 핸드셰이크 데드락 (Handshake Deadlock)
  * 원인 분석: ILA(Integrated Logic Analyzer) 디버깅 결과, CNN IP가 생성하는 tlast 신호 타이밍 불일치로 프로토콜 위반이 확인되어 데이터 흐름이 중단되었다.
  * 해결책: IP 내부의 출력 데이터 카운터 로직을 정밀하게 수정하여, 정확한 패킷 길이에 맞춰 tlast 신호를 생성하도록 변경함으로써 프로토콜을 완벽하게 준수하도록 했다.

이러한 문제 해결 경험은 프로젝트의 최종 성과를 더욱 견고하게 만들었으며, 이는 정량적, 정성적 결과로 이어졌다.

7. 결론 및 의의 (Conclusion & Significance)

본 프로젝트는 소프트웨어 AI 모델을 FPGA 하드웨어로 성공적으로 가속하는 Full-Stack 시스템을 구축함으로써 Zynq SoC 플랫폼의 잠재력을 입증했다. 이는 단순한 알고리즘 구현을 넘어, 하드웨어와 소프트웨어가 융합된 복잡한 시스템을 설계하고 구현할 수 있는 실질적인 역량을 보여주는 사례이다.

정량적 성과 종합

설계 과정에서 적용된 다양한 최적화 전략은 다음과 같은 정량적 성과로 이어졌다.

### 정량적 성과 종합
| 항목 | 최적화 전략 | 달성 효과 |
| :--- | :--- | :--- |
| 메모리 자원 | Line Buffer 설계 | BRAM/레지스터 사용량 **82% 절감** |
| 연산 자원 | Int8 양자화 | DSP 슬라이스 사용량 **75% 절감** (Float32 대비) |
| 처리 속도 | Conv2 병렬 파이프라인 | **1 Pixel / 1 Clock** 고속 처리 달성 |
| 회로 복잡도 | 시프트(>>>) 연산 | 나눗셈 로직 제거로 리소스 절약 및 타이밍 확보 |

핵심 역량 체득

본 프로젝트는 결과물 완성을 넘어 다음과 같은 핵심 엔지니어링 원칙의 중요성을 입증했다.

1. Full-Stack 시스템 설계의 중요성: AI 모델링(SW)부터 RTL 설계(HW), 시스템 통합(System)까지 전 과정을 아우르는 설계가 최종 성능을 결정함을 증명했다.
2. 하드웨어 최적화 사고방식의 가치: '어떻게 계산할까'를 넘어, **'어떻게 하면 더 적은 자원으로 더 빠르게 처리할까'**라는 하드웨어 중심의 트레이드오프 분석이 Edge AI 시스템의 핵심임을 보여주었다.
3. SoC 표준 인터페이스의 실증적 이해: AXI 프로토콜을 완벽히 이해하고 ILA를 활용한 실시간 하드웨어 디버깅을 통해 실전적인 시스템 통합 및 문제 해결 능력을 입증했다.

결론적으로, 본 프로젝트는 FPGA 기반 AI 가속기 설계의 전체 파이프라인을 성공적으로 완수했다. 이는 단순히 하나의 프로젝트 성공을 넘어, 향후 더 복잡한 신경망을 구현할 수 있는 견고한 **아키텍처적 청사진(Architectural Blueprint)**을 마련했다는 점에서 그 의의가 매우 크다.
